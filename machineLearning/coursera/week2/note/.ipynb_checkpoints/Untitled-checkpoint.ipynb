{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple features(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = number of data<br/>\n",
    "n = number of features<br/>\n",
    "$ x^{(i)}$ = input(features) of $i^{th}$ training examle<br>\n",
    "$ x^{(i)}_j$ = value of feature $j$ in $i^{th}$ traininig example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_\\theta(x) = \\theta_0 + \\theta_1x_1+\\theta_2x_2+\\theta_3x_3+\\theta_4x_4+......+\\theta_nx_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience of notation, define $x_0$ = 1\n",
    "\n",
    "$\n",
    "x = \\begin{bmatrix}\n",
    "x_0\\\\x_1\\\\x_2\\\\x_3\\\\...\\\\x_n\n",
    "\\end{bmatrix}\n",
    "$\n",
    "$\n",
    "\\theta = \\begin{bmatrix}\n",
    "\\theta_0\\\\\\theta_1\\\\\\theta_2\\\\\\theta_3\\\\...\\\\\\theta_n\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$h^{(x)}_\\theta = \\theta_0x_0 + \\theta_1x_1 + ... +\\theta_nx_n $<br>\n",
    "$ = \\theta^Tx$\n",
    "\n",
    "-> multivariate linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent for Multiple Variableas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, $\\theta$ as a vector\n",
    "\n",
    "Cost finction:<br>\n",
    "$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "Gradient descent:<br>\n",
    "Repeat{<br>\n",
    "$\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}$<br>\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "repeat until convergence:{<br>\n",
    "$\n",
    "\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^m {(h_\\theta(x^{(i)}) - y^{(i)})} \\cdot x^{(i)}_0\n",
    "$<br>\n",
    "$\n",
    "\\theta_1 := \\theta_1 - \\alpha \\frac{1}{m} \\sum_{i=1}^m {(h_\\theta(x^{(i)}) - y^{(i)})} \\cdot x^{(i)}_1\n",
    "$<br>\n",
    "$\n",
    "\\theta_2 := \\theta_2 - \\alpha \\frac{1}{m} \\sum_{i=1}^m {(h_\\theta(x^{(i)}) - y^{(i)})} \\cdot x^{(i)}_2\n",
    "$<br>\n",
    "$...$<br>\n",
    "}\n",
    "\n",
    "#### in other words\n",
    "repeat until convergence:{<br>\n",
    "$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m {(h_\\theta(x^{(i)}) - y^{(i)})} \\cdot x^{(i)}_j\n",
    "$<br>\n",
    "}\n",
    "\n",
    "for $j  := 0...n$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Gradient Descent in Pratical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "#### Idea: Make sure features are on a sililer scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g <br>\n",
    "$x_1 = size(0-2000 feet^2)$<br>\n",
    "$x_2 = number of bedrooms(1 - 5)$<br>\n",
    "\n",
    "-> a lot of time to reach best practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_1 = \\frac{size(feet^2)}{2000}$<br>\n",
    "$x_2 = \\frac{number of bed rooms}{5}$<br>\n",
    "-> Take small time\n",
    "\n",
    "-> Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "get every feature into approximately a $ -1 <= x_i <= 1 $ range<br>\n",
    "teacher says <br>\n",
    "\"If value's range is over <br>\n",
    "-3<= $x_i$ <= 3 or  $-\\frac{1}{3}$ <= $x_i$ <= $\\frac{1}{3}$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean normalization\n",
    "\n",
    "$x_i := \\frac{x_i - \\mu_i}{s_i}$\n",
    "\n",
    "$\\mu_i = $ Average of all values for feature(i)<br>\n",
    "$s_i = $ Range of values (max - min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent in Practice II - Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How decide leaning rate $\\alpha$ ?<br>\n",
    "-> plotting\n",
    "\n",
    "teacher says:<br>\n",
    "$\\alpha:$ 0.001, 0.003, 0.01, 0.03, 0.1...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\alpha$ is too small: slow convergence<br>\n",
    "If $\\alpha$ is too large: may not decrease on every eteration and thus may not converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine muliple features into one.<br>\n",
    "-> conbine $x_1$ and $x_2$ into a new feature $x_3$ by taking $x_1 \\cdot x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the behavior or curve of our hypothesis function by making it a quadratic, cubic(3次) or square(2次) root(ルート) function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cubic version:<br>\n",
    "$h(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_1^2 + \\theta_3x_1^3$\n",
    "\n",
    "root version:<br>\n",
    "$h(x) = \\theta_0 + \\theta_1x_1 + \\theta_2\\sqrt{x_1}$\n",
    "\n",
    "eg. if $x_1$ has range [1- 1000] <br>\n",
    "then range of $x_1^2$ becomes [1- 1000000] <br>\n",
    "and that of $x_1^3$ becomes [1 - 1000000000]\n",
    "\n",
    "-> so feature scaling is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent gives one way of minimizing cost function - $J(\\theta)$. <br>\n",
    "Normal equation is the another way to do it without iterate algorithm.\n",
    "\n",
    "$\\theta = (X^TX)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is no need to do feature scaling with the normal equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Gradient Descent | Normal Equation |\n",
    "|:---------------------:|:---------------------:|\n",
    "| Need to choose alpha | No need choose alpha |\n",
    "| Need many iterations| No need to iterate |\n",
    "| $O(kn^2)$ | $O(n^3)$, need to calculate inverse of $X^TX$ |\n",
    "| Work well when n is large | Slow if n is very large |\n",
    "\n",
    "- teacher says <br>\"I worry using Gradient Descent if n is larger than 10000.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equation Noninvertibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $X^TX$ is noninvertible, the common causes might be having:\n",
    "\n",
    "- Redundant features, where two features are very closely related (i.e. they are linearly dependent)\n",
    "- Too many features (e.g. m ≤ n). In this case, delete some features or use \"regularization\" (to be explained in a later lesson).\n",
    "\n",
    "Solutions to the above problems include deleting a feature that is linearly dependent with another or deleting one or more features when there are too many features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Ovtave Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
