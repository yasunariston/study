{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly detection example\n",
    "\n",
    "Aircraft engine features:<br>\n",
    "$x_1$ = heat generated<br>\n",
    "$x_2$ = vibration intensity<br>\n",
    "...\n",
    "\n",
    "### Density estimation\n",
    "\n",
    "Dataset: {$x^{(1)}, x^{(2)}, ..., x^{(m)}$}<br>\n",
    "Is $x_{test}$ anomalous\n",
    "\n",
    "### Anomaly detection example\n",
    "\n",
    "Fraud detection:<br>\n",
    "$\\rightarrow$$x^{(i)}$ = feature of user $i's$ activates<br>\n",
    "$\\rightarrow$Model $p(x)$ from date.<br>\n",
    "$\\rightarrow$Identify unusual users by checking which have $p(x) < \\epsilon$\n",
    "\n",
    "Manufacturing:<br>\n",
    "$\\rightarrow$$x^{(i)}$ = features of machine $i$<br>\n",
    "$x_1$ = memory use, $x_2$ = number of disk accesses/sec,\n",
    "$x_3$ = CPU load, $x_4$ = CPU load/network traffic, $x_n$...<br>\n",
    "$\\rightarrow$$p(x) < \\epsilon$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian (Normal) distribution\n",
    "\n",
    "Say $x \\in \\mathbb{R}$. If $x$ is a distributed Gaussian with mean $\\mu$, variance $\\sigma^2$<br>\n",
    "$\\rightarrow$$x~\\mathcal{N}(\\mu, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mu = 50\n",
    "sigma = 10\n",
    "N = 10000\n",
    "x = np.random.normal(mu, sigma, N)\n",
    "plt.hist(x, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu = 0\n",
    "sigma = [0.5, 1, 2]\n",
    "N = 10000\n",
    "x1 = np.random.normal(mu, sigma[0], N)\n",
    "x2 = np.random.normal(mu, sigma[1], N)\n",
    "x3 = np.random.normal(mu, sigma[2], N)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(x1, bins=int(100 * sigma[0]))\n",
    "ax.hist(x2, bins=int(100 * sigma[1]))\n",
    "ax.hist(x3, bins=int(100 * sigma[2]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algotirhm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density estimation\n",
    "\n",
    "Training set: {$x^{(1)}, ..., x^{(m)}$}<br>\n",
    "Each example is $x \\in \\mathbb{R}$\n",
    "\n",
    "$p(x) \\\\\n",
    "= p(x_1; \\mu_1, \\sigma^2_1)p(x_2; \\mu_2, \\sigma^2_2)p(x_3; \\mu_3, \\sigma^2_3)...p(x_n; \\mu_n, \\sigma^2_n)\\\\\n",
    "= \\Pi^n_{j=1}p(x_j; \\mu_j, \\sigma^2_j)\n",
    "$\n",
    "\n",
    "***<br>\n",
    "$\\sum_{i=1}^ni = 1 + 2 + 3 + ... + n$<br>\n",
    "$\\Pi_{i=1}^ni = 1 \\times 2 \\times 3 \\times .... \\times n$<br>\n",
    "\n",
    "### Anomaly detection algorithm\n",
    "\n",
    "1. Choose features $x_i$ that you think might be indicative of anomalous examples.\n",
    "2. Fit parameters $\\mu_1, ..., \\mu_n, \\sigma_1^2, ..., \\sigma_n^2$<br>\n",
    "    $\\mu_j = \\frac{1}{m}\\sum_{i=1}^mx_j^{(i)}$<br>\n",
    "    $\\sigma_j^2 = \\frac{1}{m}\\sum_{i=1}^m(x_j^{(i)} - \\mu_j)^2$\n",
    "3. Given new example $x$, compute $p(x)$:<br>\n",
    "    $p(x) = \\Pi_{j=1}^np(x_j; \\mu_j, \\sigma_j^2) = \\Pi_{j=1}^n\\frac{1}{\\sqrt{2\\pi}\\sigma_j}exp(-\\frac{(x_j-\\mu_j)^2}{2\\sigma_j^2})$<br>\n",
    "    Anomaly if $p(x) < \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing and Evaluating an Anomaly Detection System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The importance of real-number evaliation\n",
    "\n",
    "When developing a learning algorithm (choosing features, etc), making decisions is much easier if we have a way of evaluating our learning algoritm.<br>\n",
    "Assume we have some labeled data, of anomalous an non-anomalous examples. (y = 0 if normal, y = 1 if anomalous).<br>\n",
    "Training set: $x^{(1)}, x^{(2)}, ..., x^{(m)}$ (assume normal example/not anomalous)<br>\n",
    "Cross validation set: $(x_{cv}^{(1)}, y_{cv}^{(1)}), ..., (x_{cv}^{(m_{cv})}, y_{cv}^{(m_{cv})})$<br>\n",
    "Test set: $(x_{test}^{(1)}, y_{test}^{(1)}), ..., (x_{test}^{(m_{test})}, y_{test}^{(m_{test})})$\n",
    "\n",
    "### Aircraft engins motivationg example\n",
    "\n",
    "10000 good(normal) engines<br>\n",
    "20 frawed engines(anomalous)\n",
    "\n",
    "Training set: 6000 good engines (y = 0)<br>\n",
    "CV: 2000 good engines (y = 0), 10 anomalous (y = 1)<br>\n",
    "Test: 2000 good engines (y = 0), 10 anomalous(y = 1)\n",
    "\n",
    "Alternatice: (bad not reccomend):<br>\n",
    "Training set: 6000 good engines<br>\n",
    "CV: 4000 good engines (y = 0), 10 anomalous (y = 1)<br>\n",
    "Test: 4000 good engines (y = 0), 10 anomalous (y = 1)\n",
    "\n",
    "### Algorithm evaluation\n",
    "\n",
    "FIt model $p(x)$ on training set {$x^{(1)}, ..., x^{(m)}$}<br>\n",
    "On a cross validation/test example $x$ predict<br>\n",
    "$y = \\bigl\\{\n",
    "\\begin{array}\\\\\n",
    "1\\;\\;\\;\\verb| if | p(x) < \\epsilon\\verb| anomaly |\\\\\n",
    "0\\;\\;\\;\\verb| if | p(x) \\geq \\epsilon\\verb| normal |\\\\\n",
    "\\end{array}$\n",
    "\n",
    "Possible evaluation metrcs: <br>\n",
    "- True positive, false positive, false negative, true negative\n",
    "- Predict/Recall\n",
    "- $F_1-score$\n",
    "\n",
    "can also use cross validatoin set to choose parameter $\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection vs. Supervised Learning\n",
    "\n",
    "<b><u>Anomaly detection:</u></b><br>\n",
    "- very small number of positive example (y = 1). (0-20 is common)\n",
    "- Large number of nagative (y = 0) example\n",
    "- Many different \"types\" of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like;\n",
    "- future anomalies may look nothing like any of the anomalous example we've seen so far\n",
    "\n",
    "<b><u>Supervised learning:</u></b><br>\n",
    "- Large number of positive and negative example\n",
    "- Enough positive example for algorithm to get sense of what positive exaple likely to be similer to ones in training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing What Features to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-gaussian features\n",
    "\n",
    "to convert faussian (ex. using $log(x + c), \\sqrt{x}, x^{t}$)\n",
    "\n",
    "### Error analysis for anomaly detection\n",
    "\n",
    "Want $p(x)$ large for normal example $x$.<br>\n",
    "$p(x)$ small for anomalous examples $x$.\n",
    "\n",
    "Most common problem:<br>\n",
    "$p(x)$ is comparable (say, both large) for noemal and anomalous examples\n",
    "\n",
    "### Monitoring coputers in a data center\n",
    "\n",
    "Choosing features that might take on unusually large or small values in the event of an anomaly.<br>\n",
    "$x_1$ = memory use of computer<br>\n",
    "$x_2$ = number of disk accesses/sec<br>\n",
    "$x_3$ = CPU load<br>\n",
    "$x_4$ = network traffic<br>\n",
    "$x_5$ = [createfeature] $\\frac{\\verb| CPU load |}{\\verb| network traffic |}$<br>\n",
    "$x_6$ = [createfeature] $\\frac{(\\verb| CPU load |)^2}{\\verb| network traffic |}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Gaussian (Normal) distribution\n",
    "\n",
    "$x \\in \\mathbb{R}$. Don't model $p(x_1), p(x_2), ..., $ etc. separately.<br>\n",
    "Model $p(x)$ all in one go.<br>\n",
    "Parameters: $\\mu \\in \\mathbb{R}^n, \\Sigma \\in \\mathbb{R}^{n \\times n}$ (covariance matrix)\n",
    "\n",
    "Parameters $\\mu, \\Sigma$<br>\n",
    "$p(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{\\frac{\\pi}{2}}|\\Sigma|^{\\frac{1}{2}}}exp\\biggl(-\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu)\\biggr)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection using the Multivariate Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters $\\mu, \\Sigma$<br>\n",
    "$p(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{\\frac{\\pi}{2}}|\\Sigma|^{\\frac{1}{2}}}exp\\biggl(-\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu)\\biggr)$\n",
    "\n",
    "Paeameter fitting:<br>\n",
    "Given training set {$x^{(1)}, x^{(2)}, ..., x^{(m)}$}<br>\n",
    "$\\mu = \\frac{1}{m}\\sum_{i=1}^mx^{(i)}$<br>\n",
    "$\\Sigma = \\frac{1}{m}\\sum_{i = 1}^m(x^{(i)} - \\mu)(x^{(i)} - \\mu)^T$\n",
    "\n",
    "### Anomaly detection with the multivariate Gaussian\n",
    "\n",
    "1.Fit model $p(x)$ by setting<br>\n",
    "$\\mu = \\frac{1}{m}\\sum_{i=1}^mx^{(i)}$<br>\n",
    "$\\Sigma = \\frac{1}{m}\\sum_{i = 1}^m(x^{(i)} - \\mu)(x^{(i)} - \\mu)^T$\n",
    "\n",
    "2.Given a new example $x$, compute<br>\n",
    "$p(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{\\frac{\\pi}{2}}|\\Sigma|^{\\frac{1}{2}}}exp\\biggl(-\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu)\\biggr)$\n",
    "\n",
    "Flag an anomaly if $p(x) < \\epsilon$\n",
    "\n",
    "### Relationship to original model\n",
    "\n",
    "Original model: $p(x) = p(x_1; \\mu_1, \\sigma_1^2) \\times p(x_2; \\mu_2, \\sigma_2^2) \\times ... \\times p(x_n; \\mu_n, \\sigma_n^2)$\n",
    "Multivariate Gaussian: $p(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{\\frac{\\pi}{2}}|\\Sigma|^{\\frac{1}{2}}}exp\\biggl(-\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu)\\biggr)$\n",
    "\n",
    "### Original model vs Multivariate Gaussian\n",
    "\n",
    "<b><u>Original model</u></b>\n",
    "- Manually create features to capture anomalies where $x_1, x_2$ take unusual combinations of values\n",
    "- Computatinoally cheaper (alternatively, scales better to large n)<br> n = 10,000,  n = 100,000\n",
    "- OK even if $m$ (tainining set size) is small\n",
    "\n",
    "<b><u>Multivariate Gaussian</u></b>\n",
    "- Automatically captures correlations between features\n",
    "- Computationally more expensive\n",
    "- Must have $m > n$, or else $\\Sigma$ is non-invertible <br>\n",
    "$m \\geq 10n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "<b><u>Question1</u></b><br>\n",
    "For which of the following problems would anomaly detection be a suitable algorithm?\n",
    "- Given data from credit card transactions, classify each transaction according to type of purchase (for example: food, transportation, clothing).\n",
    "- From a large set of primary care patient records, identify individuals who might have unusual health conditions.\n",
    "- In a computer chip fabrication plant, identify microchips that might be defective.\n",
    "- From a large set of hospital patient records, predict which patients have a particular disease (say, the flu).\n",
    "\n",
    "<b><u>Question2</u></b><br>\n",
    "Suppose you have trained an anomaly detection system for fraud detection, and your system that flags anomalies when p(x)p(x) is less than \\varepsilonε, and you find on the cross-validation set that it mis-flagging far too many good transactions as fradulent. What should you do?\n",
    "- Increase $\\epsilon$\n",
    "- Decrease $\\epsilon$\n",
    "\n",
    "<b><u>Question3</u></b><br>\n",
    "Suppose you are developing an anomaly detection system to catch manufacturing defects in airplane engines. You model uses<br>\n",
    "$p(x) = \\Pi^n_{j=1}p(x_j; \\mu_j, \\sigma^2_j)$<br>\n",
    "You have two features $x_1$ = vibration intensity, and $x_2$ = heat generated. Both $x_1$ and $x_2$ take on values between 0 and 1 (and are strictly greater than 0), and for most \"normal\" engines you expect that $x_1 \\approx x_2$. One of the suspected anomalies is that a flawed engine may vibrate very intensely even without generating much heat (large $x_1$, small $x_2$), even though the particular values of $x_1$ and $x_2$ may not fall outside their typical ranges of values. What additional feature $x_3$ should you create to capture these types of anomalies:\n",
    "- $x_3 = x_1 \\times x_2$\n",
    "- $x_3 = x_1 + x_2$\n",
    "- $x_3 = \\frac{x_1}{x_2}$\n",
    "- $x_3 = x_1^2 \\times x_2$\n",
    "\n",
    "<b><u>Question4</u></b><br>\n",
    "Which of the following are true? Check all that apply.\n",
    "- When choosing features for an anomaly detection system, it is a good idea to look for features that take on unusually large or small values for (mainly the) anomalous examples.\n",
    "- If you are developing an anomaly detection system, there is no way to make use of labeled data to improve your system.\n",
    "- If you do not have any labeled data (or if all your data has label $y=0$), then is is still possible to learn $p(x)$, but it may be harder to evaluate the system or choose a good value of $\\epsilon$.\n",
    "- If you have a large labeled training set with many positive examples and many negative examples, the anomaly detection algorithm will likely perform just as well as a supervised learning algorithm such as an SVM.\n",
    "\n",
    "<b><u>Question5</u></b><br>\n",
    "You have a 1-D dataset $\\{x^{(1)}, \\ldots, x^{(m)}$\n",
    " } and you want to detect outliers in the dataset. You first plot the dataset and it looks like this:\n",
    "\n",
    "[graph]\n",
    "\n",
    "Suppose you fit the gaussian distribution parameters $\\mu_1$ and $\\sigma_1^2$ to this dataset. Which of the following values for $\\mu_1$ and $\\sigma_1^2$ might you get?\n",
    "- $\\mu=−3, \\sigma_1^2 = 4$\n",
    "- $\\mu=−6, \\sigma_1^2 = 4$\n",
    "- $\\mu=−3, \\sigma_1^2 = 2$\n",
    "- $\\mu=−6, \\sigma_1^2 = 2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Fomulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Predictiong motive ratings\n",
    "\n",
    "User rate movies using <s>one</s> <font color=\"red\">zero</font> to five stars\n",
    "\n",
    "|type|Movie|Alice(1)|Bob(2)|Carol(3)|Dave(4)|\n",
    "|:-----:|:-----:|:---------:|:--------:|:---------:|:---------:|\n",
    "|love|Love at last|5|5|0|0|\n",
    "|love|Romance forever|5|?|?|0|\n",
    "|love|Cute pupplies of love|?|4|0|?|\n",
    "|action|Nonstop car chase|0|0|5|4|\n",
    "|action|Sword vs. karate|0|0|5|?|\n",
    "\n",
    "$n_u$ = no.users<br>\n",
    "$n_m$ = no.movies<br>\n",
    "$r(i, j)$ = 1 if user $j$ has rated movie $i$<br>\n",
    "$y^{(i, j)}$ = rating given by user $j$ to movie $i$ (defined only if $r(i, j) = 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based Reccomendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contetnt-based recommender system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|type|Movie|Alice(1)|Bob(2)|Carol(3)|Dave(4)|$x_1$<br>(romance)|$x_2$<br>(action)|\n",
    "|:-----:|:-----:|:---------:|:--------:|:---------:|:---------:|:-------:|:-------:|\n",
    "|romance|Love at last|5|5|0|0|0.9|0|\n",
    "|romance|Romance forever|5|?|?|0|1.0|0.01|^{(1)}\n",
    "|romance|Cute pupplies of love|?|4|0|?|0.99|0|\n",
    "|action|Nonstop car chase|0|0|5|4|0.1|1.0|\n",
    "|action|Sword vs. karate|0|0|5|?|0|0.9|\n",
    "\n",
    "$n_u = 4, n_m = 5, x_0 = 1$<br>\n",
    "$x^{(1)} = \\begin{bmatrix}\n",
    "1\\\\0.9\\\\0\n",
    "\\end{bmatrix}$\n",
    "$x^{(2)} = \\begin{bmatrix}\n",
    "1\\\\1.0\\\\0.01\n",
    "\\end{bmatrix}$\n",
    "$x^{(3)} = ...$\n",
    "\n",
    "For each user $j$, learn a parameter $\\theta^{(i)} \\in \\mathbb{R}^3$. Predict user $j$ as rating move $i$ with $(\\theta^{(i)})^Tx^{(i)}$ stars.\n",
    "\n",
    "$x^{(3)} = \\begin{bmatrix}\n",
    "1\\\\0.99\\\\0\n",
    "\\end{bmatrix}$\n",
    "$\\theta^{(1)} = \\begin{bmatrix}\n",
    "0\\\\5\\\\0\n",
    "\\end{bmatrix}$<br>\n",
    "$(\\theta^{(1)})^Tx^{(3)} = \\int x0.99 = 4.95$\n",
    "\n",
    "### Problem formulation\n",
    "\n",
    "$r(i, j) = 1$ if user $j$ has rated movie $i$ (0 otherwise)<br>\n",
    "$r^{(o, j)}$ = rating by user $j$ on movie $i$ (If defined)\n",
    "\n",
    "$\\theta^{(j)}$ = parameter vector for user $i$<br>\n",
    "$x^{(i)}$ = feature vector for movie $i$<br>\n",
    "For user $j$, movie $i$, predited rating: $(\\theta^{(j)})^T(x^{(i)})$<br>\n",
    "\n",
    "$m^{(j)}$ = no. of movies rated by user $j$<br>\n",
    "To leatn $\\theta^{(j)}$:<br>\n",
    "$min_{\\theta^{(j)}}\\frac{1}{2m^{(j)}}\\Sigma_{i:r(i,j) = 1}\\biggl((\\theta^{(j))^T(x^{(i)})} - y^{(i, j)}\\biggr)^2 + \\frac{\\lambda}{2m^{(j)}}\\sum_{k = 1}^n(\\theta_k^{j})^2$\n",
    "\n",
    "### Optimization objective:\n",
    "To learn $\\theta^{(j)}$ (parameter for user $j$):<br>\n",
    "$min_{\\theta^{(j)}}\\frac{1}{2}\\sum_{i:r(i,j) = 1}\\biggl((\\theta^{(j))^T(x^{(i)})} - y^{(i, j)}\\biggr)^2 + \\frac{\\lambda}{2}\\sum_{k = 1}^n(\\theta_k^{j})^2$\n",
    "\n",
    "To learn $\\theta^{(1)}, \\theta^{(2)}, ..., \\theta^{(n_u)}$:<br>\n",
    "$min_\\theta^{(1)}, ..., \\theta^(n_u)\\frac{1}{2}\\sum_{j=1}^{n_u}\\sum_{i:r(i, j)=1} + \\frac{\\lambda}{2}\\sum_{j=1}^{n_u}\\sum_{k=1}^n(\\theta_k^{(j)})^2$\n",
    "\n",
    "### Opatimiaztion algorithm:\n",
    "$min_\\theta^{(1)}, ..., \\theta^(n_u)\\frac{1}{2}\\sum_{j=1}^{n_u}\\sum_{i:r(i, j)=1} + \\frac{\\lambda}{2}\\sum_{j=1}^{n_u}\\sum_{k=1}^n(\\theta_k^{(j)})^2$\n",
    "\n",
    "Gradient discent update:<br>\n",
    "$\\theta_k^{(j)} := \\theta_k^{(j)} - \\alpha \\sum_{i:r(i, j) = 1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i, j)})x_k^{(i)}$ (for k = 0) <br>\n",
    "$\\theta_k^{(j)} := \\theta_k^{(j)} - \\alpha\\biggl(\\sum_{i:r(i, j) = 1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i, j)})x_k^{(i)} + \\lambda\\theta_j^{(j)}\\biggr)$ (for k ≠ 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem motivation\n",
    "\n",
    "|type|Movie|Alice(1)|Bob(2)|Carol(3)|Dave(4)|$x_1$<br>(romance)|$x_2$<br>(action)|\n",
    "|:-----:|:-----:|:---------:|:--------:|:---------:|:---------:|:-------:|:-------:|\n",
    "|romance|Love at last|5|5|0|0|?|?|\n",
    "|romance|Romance forever|5|?|?|0|?|?|\n",
    "|romance|Cute pupplies of love|?|4|0|?|?|?|\n",
    "|action|Nonstop car chase|0|0|5|4|?|?|\n",
    "|action|Sword vs. karate|0|0|5|?|?|?|\n",
    "\n",
    "$\\theta^{(1)} = \\begin{bmatrix}0\\\\5\\\\0\\end{bmatrix}$\n",
    "$\\theta^{(2)} = \\begin{bmatrix}0\\\\5\\\\0\\end{bmatrix}$\n",
    "$\\theta^{(3)} = \\begin{bmatrix}0\\\\0\\\\5\\end{bmatrix}$\n",
    "$\\theta^{(4)} = \\begin{bmatrix}0\\\\0\\\\5\\end{bmatrix}$\n",
    "\n",
    "### Optimization algorithm\n",
    "\n",
    "Given $\\theta^{(1)}, ..., \\theta^{n_u}$, to learn $x^{(i)}$<br>\n",
    "$\\rightarrow min_{x^{(i)}}\\frac{1}{2}\\sum_{j:r(i, j) = 1}((\\theta^{(j)})^Tx^{(i)} - y^{(i, j)})^2 + \\frac{\\lambda}{2}\\sum_{k=1}^n(x_k^{(i)})^2$\n",
    "\n",
    "Given $\\theta^{(1)}, ..., \\theta^{(n_u)}$, to learn $x^{(1)}, ..., x^{(n_m)}$:<br>\n",
    "$\\rightarrow min_{x^{(1)}, ..., x^{n_m}}\\frac{1}{2}\\sum_{i=1}^{n_m}\\sum_{j:r(i, j)=1}((\\theta)^Tx^{(i) - y^{(i, j)}})^2 + \\frac{\\lambda}{2}\\sum_{i=1}^{n_m}\\sum_{k = 1}^n(x_k^{(i)})^2$\n",
    "\n",
    "### Collaborative filtering\n",
    "\n",
    "Given $x^{(1)}, ..., x^{n_m}$ (and movie ratings),<br>\n",
    "can estimate $\\theta^{(1), ..., \\theta^{(n_u)}}$\n",
    "\n",
    "Given $\\theta^{(1), ..., \\theta^{(n_u)}}$ (and movie ratings),<br>\n",
    "can estimate $x^{(1)}, ..., x^{n_m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Algorithm\n",
    "\n",
    "1. Initialize $x^(1), ..., x^{(n)}, \\theta^{(1)}, ..., \\theta^{(n_m)}$ to small random values.\n",
    "2. Minimize $J(x^(1), ..., x^{(n)}, \\theta^{(1)}, ..., \\theta^{(n_m)})$ using gradient descent (or an advanced optimization algorithm). E.g. for every $j = 1, ..., n_m, i = 1, ..., n_m$:<br>\n",
    "$x_k^{(i)} = x_k^{(i)} - \\alpha\\biggl(\\sum_{j:r(i, j) = 1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i, j)})\\theta_k^{(j)} + \\lambda x_k^{(i)}\\biggr)$ <br>\n",
    "$\\theta_k^{(i)} = \\theta_k^{(i)} - \\alpha\\biggl(\\sum_{j:r(i, j) = 1} ((\\theta^{(j)})^Tx^{(i)} - y^{(i, j)})\\theta_k^{(j)} + \\lambda \\theta_k^{(i)}\\biggr)$ <br>\n",
    "3. For a user with parameter $\\theta$ and a movie with (learned) features $x$, predict a star rating of $\\theta^Tx$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization: Low Rank Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering\n",
    "\n",
    "$Y = \\begin{bmatrix}\n",
    "5&5&0&0\\\\\n",
    "5&?&?&0\\\\\n",
    "?&4&0&?\\\\\n",
    "0&0&5&4\\\\\n",
    "0&0&5&0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Preadict ratings:<br>\n",
    "$\\begin{bmatrix}\n",
    "(\\theta^{(1)})^T(x^{(1)})&(\\theta^{(2)})^T(x^{(1)})&\\cdots&(\\theta^{(n_u)})^T(x^{(1)})\\\\\n",
    "(\\theta^{(1)})^T(x^{(2)})&(\\theta^{(2)})^T(x^{(2)})&\\cdots&(\\theta^{(n_u)})^T(x^{(2)})\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "(\\theta^{(1)})^T(x^{(n_m)})&(\\theta^{(2)})^T(x^{(n_m)})&\\cdots&(\\theta^{(n_u)})^T(x^{(n_m)})\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "### Finding related movies\n",
    "\n",
    "For each product $i$, we learn a feature vector $x^{(i)} \\in \\mathbb{R}$.\n",
    "\n",
    "How to find movie $j$ related movie $i$?\n",
    "\n",
    " 5 most similer movies to movie $i$:<br>\n",
    " FInd 5 movies $j$ with the smallest $||x^{(i)} - x^{(j)}||$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementational Detail: Mean Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Normalization:\n",
    "\n",
    "$Y = \\begin{bmatrix}\n",
    "5&5&0&0&?\\\\\n",
    "5&?&?&0&?\\\\\n",
    "?&4&0&?&?\\\\\n",
    "0&0&5&4&?\\\\\n",
    "0&0&5&0&?\n",
    "\\end{bmatrix}$\n",
    "$\\mu = \\begin{bmatrix}\n",
    "2.5\\\\\n",
    "2.5\\\\\n",
    "2\\\\\n",
    "2.25\\\\\n",
    "1.25\n",
    "\\end{bmatrix}$\n",
    "$Y = \\begin{bmatrix}\n",
    "2.5&2.5&-2.5&-2.5&?\\\\\n",
    "2.5&?&?&-2.5&?\\\\\n",
    "?&2&-2&?&?\\\\\n",
    "-2.25&-2.25&2.75&1.75&?\\\\\n",
    "-1.25&-1.25&3.75&-1.25&?\n",
    "\\end{bmatrix}$\n",
    "\n",
    "For user $j$, on movie $i$ predict:<br>\n",
    "$\\rightarrow (\\theta^{(j)})^T(x^{(i)}) + \\mu_i$\n",
    "\n",
    "User 5(Eve) = $\\begin{bmatrix}0\\\\0\\end{bmatrix}$<br>\n",
    "$(\\theta^{(s)})^T(x^{(i)}) + \\mu_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "<b><u>Question1:</u></b><br>\n",
    "Suppose you run a bookstore, and have ratings (1 to 5 stars) of books. Your collaborative filtering algorithm has learned a parameter vector $\\theta^{(j)}$ for user $j$, and a feature vector $x^{(i)}x$ for each book. You would like to compute the \"training error\", meaning the average squared error of your system's predictions on all the ratings that you have gotten from your users. Which of these are correct ways of doing so (check all that apply)? For this problem, let $m$ be the total number of ratings you  have gotten from your users. (Another way of saying this is that \n",
    "\n",
    "\n",
    "<b><u>Question2:</u></b><br>\n",
    "In which of the following situations will a collaborative filtering system be the most appropriate learning algorithm (compared to linear or logistic regression)?\n",
    "- You run an online bookstore and collect the ratings of many users. You want to use this to identify what books are \"similar\" to each other (i.e., if one user likes a certain book, what are other books that she might also like?)\n",
    "- You're an artist and hand-paint portraits for your clients. Each client gets a different portrait (of themselves) and gives you 1-5 star rating feedback, and each client purchases at most 1 portrait. You'd like to predict what rating your next customer will give you.\n",
    "- You own a clothing store that sells many styles and brands of jeans. You have collected reviews of the different styles and brands from frequent shoppers, and you want to use these reviews to offer those shoppers discounts on the jeans you think they are most likely to purchase\n",
    "- You manage an online bookstore and you have the book ratings from many users. You want to learn to predict the expected sales volume (number of books sold) as a function of the average rating of a book.\n",
    "\n",
    "<b><u>Question3:</u></b><br>\n",
    "You run a movie empire, and want to build a movie recommendation system based on collaborative filtering. There were three popular review websites (which we'll call A, B and C) which users to go to rate movies, and you have just acquired all three companies that run these websites. You'd like to merge the three companies' datasets together to build a single/unified system. On website A, users rank a movie as having 1 through 5 stars. On website B, users rank on a scale of 1 - 10, and decimal values (e.g., 7.5) are allowed. On website C, the ratings are from 1 to 100. You also have enough information to identify users/movies on one website with users/movies on a different website. Which of the following statements is true?\n",
    "- You can merge the three datasets into one, but you should first normalize each dataset's ratings (say rescale each dataset's ratings to a 1-100 range).\n",
    "- It is not possible to combine these websites' data. You must build three separate recommendation systems.\n",
    "- You can combine all three training sets into one without any modification and expect high performance from a recommendation system.\n",
    "- Assuming that there is at least one movie/user in one database that doesn't also appear in a second database, there is no sound way to merge the datasets, because of the missing data.\n",
    "\n",
    "<b><u>Question4:</u></b><br>\n",
    "Which of the following are true of collaborative filtering systems? Check all that apply.\n",
    "- Even if each user has rated only a small fraction of all of your products (so $r(i,j)=0$ for the vast majority of $(i,j)$ pairs), you can still build a recommender system by using collaborative filtering.\n",
    "- Suppose you are writing a recommender system to predict a user's book preferences. In order to build such a system, you need that user to rate all the other books in your training set.\n",
    "- For collaborative filtering, it is possible to use one of the advanced optimization algoirthms (L-BFGS/conjugate gradient/etc.) to solve for both the $x^{(i)}$'s and $\\theta^{(j)}$ 's simultaneously.\n",
    "- For collaborative filtering, the optimization algorithm you should use is gradient descent. In particular, you cannot use more advanced optimization algorithms (L-BFGS/conjugate gradient/etc.) for collaborative filtering, since you have to solve for both the $x^{(i)}$'s and $\\theta^{(j)}$'s simultaneously.\n",
    "\n",
    "<b><u>Question5:</u></b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
