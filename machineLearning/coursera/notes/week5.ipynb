{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network(classification)\n",
    "\n",
    "$\\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ......, (x^{(m)}, y^{(m)})\\}$<br>\n",
    "$L=$total number of layers in network<br>\n",
    "$s_1=$number of units (not counting bias unit) in layer $l$<br>\n",
    "$K=$number of output units/classes\n",
    "\n",
    "<u>Binary classification</u>\n",
    "- $y$ = 0 or 1\n",
    "- 1 output unit\n",
    "    \n",
    "<u>Multi-class classification</u>\n",
    "- $y \\in \\mathbb{R}$\n",
    "- K output uints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "Logistic regression:<br>\n",
    "$j(\\theta) = -\\frac{1}{m}\\biggl[\\sum^m_{i=1}y^{(i)}log(x^{(i)}) + (1 - y^{(i)})log(1 - h_\\theta(x^{(i)}))\\biggr] + \\frac{\\lambda}{2m}\\sum^n_{j=1}\\theta^2$\n",
    "\n",
    "Neural network:<br>\n",
    "$h_\\Theta(x)\\in\\mathbb{R}^K\\;\\;\\;(h_\\Theta(i))_i = i^{th}$ output<br>\n",
    "$J(\\Theta) = -\\frac{1}{m}\\biggl[\\sum^m_{i=1}\\sum^K_{k=1}y^{(i)}_klog(h_\\Theta(x^{(i)}))_k + (1 - y_k^{(i)})log(1 - h_\\Theta(x^{(i)}))_k\\biggr] + \\frac{\\lambda}{2m}\\sum^{L-1}_{l=1}\\sum^{s_l}_{i=1}\\sum^{s_l + 1}_{j=1}(\\Theta^{(l)}_{j,i})^2$\n",
    "\n",
    "- the double sum simply adds up the logistic regression costs calculated for each cell in the output layer\n",
    "- the triple sum simply adds up the squares of all the individual Θs in the entire network\n",
    "- the i in the triple sum does <u>not</u> refer to training example i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient comuputation\n",
    "\n",
    "$J(\\Theta) = -\\frac{1}{m}\\biggl[\\sum^m_{i=1}\\sum^K_{k=1}y^{(i)}_klog(h_\\Theta(x^{(i)}))_k + (1 - y_k^{(i)})log(1 - h_\\Theta(x^{(i)}))_k\\biggr] \\\\+ \\frac{\\lambda}{2m}\\sum^{L-1}_{l=1}\\sum^{s_l}_{i=1}\\sum^{s_l + 1}_{j=1}(\\Theta^{(l)}_{j,i})^2$\n",
    "\n",
    "$min_\\Theta J(\\Theta)$<br>\n",
    "Need code to cumpute:\n",
    "- $J(\\Theta)$\n",
    "- $\\frac{\\partial}{\\partial\\Theta^{(l)}_{i, j}}J(\\Theta)$\n",
    "\n",
    "Given one training example(x , y):<br>\n",
    "Forward propagation:<br>\n",
    "    $\n",
    "    a^{(1)} = x\\\\\n",
    "    z^{(2)} = \\Theta^{(1)}a^{(1)}\\\\\n",
    "    a^{(2)} = g(z^{(2)})\\;(add\\,a^{(2)}_0)\\\\\n",
    "    z^{(3)} = \\Theta^{(2)}a^{(2)}\\\\\n",
    "    a^{(3)} = g(z^{(3)})\\;(add\\,a^{(3)}_0)\\\\\n",
    "    z^{(4)} = \\Theta^{(3)}a^{(3)}\\\\\n",
    "    a^{(4)} = h_\\Theta(x) = a(z^{(4)})\n",
    "    $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient computation: Backpropagation algorithm\n",
    "\n",
    "Intuition: $\\delta^{(l)}_j$ = \"error\" of node $j$ in layer $l$\n",
    "\n",
    "For each output unit(layer L = 4)<br>\n",
    "$\n",
    "\\delta^{(4)}_j = a^{(4)}_j - y_j\\\\\n",
    "\\delta^{(3)} = (\\Theta^{(3)})^T\\delta^{(4)}.* g'(z^{(3)})\\\\\n",
    "\\delta^{(2)} = (\\Theta^{(2)})^T\\delta^{(3)}.* g'(z^{(2)})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation algorithm\n",
    "\n",
    "Training set $\\{(x^{(1)}, y^{(1)}), ..., (x^{(m)}, y^{(m)})\\}$<br>\n",
    "Set $\\Delta^{(l)}_{i, j} = 0$ (for all $l. i. j$)<br>\n",
    "\n",
    "For $i\\;=\\;1\\;to\\;m${<br>\n",
    "Set $a^{(1)} = x^{(i)}$<br>\n",
    "    Perform forward propagation to compute $a^{(l)}$ for $l = 2, 3, ..., L$<br>\n",
    "    Using $y^{(i)}$, compute $\\delta^{(L)} = a^{(L)} - y^{(i)}$<br>\n",
    "    Compute $\\delta^{(L-1)}, \\delta^{(L-2)}, ...., \\delta^{(2)}$<br>\n",
    "    $\\Delta^{(l)}_{i, j} := \\Delta^{(l)}_{i, j} + a^{(l)}_j\\delta^{l+1}_i$<br>\n",
    "}<br>\n",
    "$D^{(l)}_{i, j} := \\frac{1}{m}\\Delta^{(l)}_{i, j} + \\lambda\\Theta^{(l)}_{i, j}$ if j ≠ 0<br>\n",
    "$D^{(l)}_{i, j} := \\frac{1}{m}\\Delta^{(l)}_{i, j}$  if j = 0\n",
    "\n",
    "$\\frac{\\partial}{\\partial^{(l)}_{i,j}}J(\\Theta) = D^{(l)}_{i, j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Intution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Note: Unrolling Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced optimization\n",
    "\n",
    "functon [JVal, gradient] = costFunction(Theta)<br>\n",
    "...<br>\n",
    "optTheta = fminunc(@costFunction, initialTheta, options)\n",
    "\n",
    "Nerural Network(L=4):<br>\n",
    "    $\\Theta^{(1)}, \\Theta^{(2)}, \\Theta^{(3)}$ - matrices(Theta1, Theta2, Theta3)<br>\n",
    "    $D^{(1)}, D^{(2)}, D{(3)}$ - matrices(D1, D2, D3)<br>\n",
    "\"Unroll\" into vectors\n",
    "\n",
    "#### Example\n",
    "$\n",
    "s_ 1 = 10, s_2 = 10, s_3 = 1\\\\\n",
    "\\Theta^{(1)}\\in\\mathbb{R}^{10\\times11}, \\Theta^{(2)}\\in\\mathbb{R}^{10\\times11}, \\Theta^{(3)}\\in\\mathbb{R}^{1\\times11}\\\\\n",
    "D^{(1)}\\in\\mathbb{R}^{10\\times11}, D^{(2)}\\in\\mathbb{R}^{10\\times11},D^{(3)}\\in\\mathbb{R}^{1\\times11}\\\\\n",
    "$\n",
    "\n",
    "ThetaVec = [Theta1(:); Theta2(:); Theta3(:);];<br>\n",
    "DVec = [D1(:); D2(:); D3(:)];\n",
    "\n",
    "Theta1 = reshape(thetaVec(1:100), 10, 11);<br>\n",
    "Theta2 = reshape(thetaVec(111:220), 10, 11);<br>\n",
    "Theta3 = reshape(thetaVec(221:231), 1, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Algorithm\n",
    "\n",
    "Have a initial parameters $\\Theta^{(1)}, \\Theta^{(2)}, \\Theta{(3)}$.<br>\n",
    "Unroll to get initialTheta to pass to<br>\n",
    "fminunc(@costFnction, initialTheta, options)\n",
    "\n",
    "function[jval, gradientVec] = costFunction(thetaVec)<br>\n",
    "From thetaVec, get $\\Theta^{(1)}, \\Theta^{(2)}, \\Theta^{(3)}$<br>\n",
    "Use forward prop/back prop to compute $D^{(1)}, D^{(2)}, D^{(3)}$ and $J(\\Theta)$.<br>\n",
    "Unroll $D^{(1)}, D^{(2)}, D^{(3)}$ to get gradientVec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradirnt Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\frac{\\partial}{\\partial\\Theta}J(\\Theta)\\approx \\frac{J(\\Theta + \\epsilon) - J(\\Theta - \\epsilon)}{2\\epsilon}\n",
    "$\n",
    "\n",
    "With multiple theta matrices, we can approxmate the derivative with respect to $\\Theta_j$ as follows:\n",
    "\n",
    "$\n",
    "\\frac{\\partial}{\\partial\\Theta}J(\\Theta)\\approx \\frac{J(\\Theta_1, ....\\Theta_j + \\epsilon, ...., \\Theta_n) - J(\\Theta_1, ....\\Theta_j - \\epsilon, ...., \\Theta_n)}{2\\epsilon}\n",
    "$\n",
    "\n",
    "($\\epsilon=10^{-4}$ makes good math works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Note:\n",
    "\n",
    "- Implement backprop to compute DVec(unrolled $D^{(1)}, D^{(2)}, D^{(3)}$)\n",
    "- Implement numerical gradient check to compute gradApprox.\n",
    "- Make sure they give similer values.\n",
    "- Turn off gradient cheking. Using backprop code for learning.\n",
    "\n",
    "### Important:\n",
    "\n",
    "- Be sure to disable your gradient checking code before training your classfier. If you run numerical gradient computation on every iteration of gradient descent(or in the inner loop of costFunction(...)) your code will be very slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Initialization (Initial valie of $\\Theta$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random initialization; Symmetry breaking\n",
    "\n",
    "<u>Initializing all theta weights to zero does not work with neural networks.</u> When we backpropagate, all nodes will update to the same value repeatedly. Instead we can randomly initialize our weights for our \\ThetaΘ matrices using the following method:\n",
    "\n",
    "Initializa each $\\Theta_{i, j}^{(l)}$ to random value in $[-\\epsilon, \\epsilon]$<br>\n",
    "(i.e $-\\epsilon \\leq \\Theta_{i, j}^{(l)} \\leq\\epsilon$)\n",
    "\n",
    "E.g.<br>\n",
    "Theta1 = rand(10, 11) * (2 * INIT_EPSILON) - INIT_EPSILON;<br>\n",
    "Theta2 = rand(10, 11) * (2 * INIT_EPSILON) - INIT_EPSILON;<br>\n",
    "Theta3 = rand(1, 11) * (2 * INIT_EPSILON) - INIT_EPSILON;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training neural network\n",
    "\n",
    "Pick a net work architecture(Connrctivity pattern between neurons)\n",
    "\n",
    "- No. of input units: Dimension of features $x^{(i)}$\n",
    "- No. output units: Number of classes\n",
    "- Reasonable default: 1 hidden layer, or if 1 > hidden layer, have same no. of hidden units in every layer (usually the more the better)\n",
    "\n",
    "\n",
    "1. Randomly initialize weights\n",
    "2. Implement code forward propagation to get $h_\\Theta(x^{(i)})$ for any $x^{(i)}$\n",
    "3. Implement code to compute cost function $J(\\Theta)$\n",
    "4. Implement backprop to compute partial derivatives $\\frac{\\partial}{\\partial\\Theta_{i, j}^{(l)}}J(\\Theta)$\n",
    "5. Use gradient checking to compare $\\frac{\\partial}{\\partial\\Theta_{j, k}^{(l)}}$ computed using backpropagation vs. using numerical estimate of gradient of $J(\\Theta)$.\n",
    "6. Use gradient descent or advanced optimization method with backpropagation to try to minimize $J(\\Theta)$ as a function of parameters $\\Theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Question1</u><br>\n",
    "You are training a three layer neural network and would like to use backpropagation to compute the gradient of the cost function. In the backpropagation algorithm, one of the steps is to update\n",
    "\n",
    "$\\Delta_{i,j}^{(2)} = \\Delta_{i,j}^{(2)} + \\delta^{(3)} * (a^{(2)})^T$ <br>\n",
    "for every $i, j$. Which of the following is a correct vectorization of this step?\n",
    "- $\\Delta^{(2)} = \\Delta^{(2)} + \\delta^{(3)} * (a^{(2)})^T$ [selected]\n",
    "- $\\Delta^{(2)} = \\Delta^{(2)} + \\delta^{(3)} * (a^{(3)})^T$\n",
    "- $\\Delta^{(2)} = \\Delta^{(2)} + \\delta^{(2)} * (a^{(2)})^T$\n",
    "- $\\Delta^{(2)} = \\Delta^{(2)} + (a^{(2)})^T * \\delta^{(3)}$\n",
    "\n",
    "<u>Question2</u><br>\n",
    "Suppose Theta1 is a 5x3 matrix, and Theta2 is a 4x6 matrix. You set  = thetaVec=[Theta1(:);Theta2(:)]. Which of the following correctly recovers  Theta2?\n",
    "- reshape(thetaVec(16:39),4,6) [selected]\n",
    "- reshape(thetaVec(15:38),4,6)\n",
    "- reshape(thetaVec(16:24),4,6)\n",
    "- reshape(thetaVec(15:39),4,6)\n",
    "- reshape(thetaVec(16:39),6,4)\n",
    "\n",
    "<u>Question3</u><br>\n",
    "Let $J(\\theta) = 3\\theta^4$. Let $\\theta = 1,$ and $\\epsilon = 0.01$. Use the formula $\\frac{J(\\theta+\\epsilon) - J(\\theta - \\epsilon)}{2\\epsilon}$ to numerically cumpute an approximation to the derivative at $\\theta = 1$. What value do you get? (When $\\theta = 1$, the true/exact derivatice is $\\frac{dJ(\\theta)}{d\\theta}$ = 12)\n",
    "- 6\n",
    "- 12\n",
    "- 12.0012 [selected]\n",
    "- 11.9988\n",
    "\n",
    "<u>Question4</u><br>\n",
    "Which of the following statements are true? Check all that apply.\n",
    "- Using gradient checking can help verify if one's implementation of backpropagation is bug-free. [selected]\n",
    "- Gradient checking is useful if we are using one of the advanced optimization methods (such as in fminunc) as our optimization algorithm. However, it serves little purpose if we are using gradient descent.\n",
    "- Computing the gradient of the cost function in a neural network has the same efficiency when we use backpropagation or when we numerically compute it using the method of gradient checking.\n",
    "- For computational efficiency, after we have performed gradient checking to verify that our backpropagation code is correct, we usually disable gradient checking before using backpropagation to train the network. [selected]\n",
    "\n",
    "<u>QUestion5</u><br>\n",
    "Which of the following statements are true? Check all that apply.\n",
    "- Suppose that the parameter $\\Theta^{(1)}$ is a square matrix (meaning the number of rows equals the number of columns). If we replace $\\Theta^{(1)}$ with its transpose $(\\Theta^{(1)})^T$, then we have not changed the function that the network is computing.\n",
    "- Suppose we are using gradient descent with learning rate $\\alpha$. For logistic regression and linear regression, $J(\\theta) $ was a convex optimization problem and thus we did not want to choose a learning rate $\\alpha$ that is too large. For a neural network however, $J(\\Theta)$ may not be convex, and thus choosing a very large value of $\\alpha$ can only speed up convergence.\n",
    "- If we are training a neural network using gradient descent, one reasonable \"debugging\" step to make sure it is working is to plot $J(\\Theta)$ as a function of the number of iterations, and make sure it is decreasing (or at least non-increasing) after each iteration.　[selected]\n",
    "- Suppose we have a correct implementation of backpropagation, and are training a neural network using gradient descent. Suppose we plot $J(\\Theta)$ as a function of the number of iterations, and find that it is increasing rather than decreasing. One possible cause of this is that the learning rate $\\alpha$ is too large. [selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
